#!/usr/bin/env python3
"""
Ù…Ø¬Ù…ÙˆØ¹Ø© Ø³ÙƒØ±ÙŠØ¨ØªØ§Øª Ù„Ø¥Ø¯Ø§Ø±Ø© ÙˆØªØ­Ù„ÙŠÙ„ Logs
"""

import json
import shutil
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from typing import Dict, List, Any

# =============================================================================
# cleanup_logs.py - ØªÙ†Ø¸ÙŠÙ Logs Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
# =============================================================================

def cleanup_old_logs(days_to_keep: int = 30, dry_run: bool = False):
    """
    Ø­Ø°Ù logs Ø£Ù‚Ø¯Ù… Ù…Ù† Ø¹Ø¯Ø¯ Ù…Ø¹ÙŠÙ† Ù…Ù† Ø§Ù„Ø£ÙŠØ§Ù…
    
    Args:
        days_to_keep: Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ù„Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ù€ logs
        dry_run: Ø¥Ø°Ø§ ÙƒØ§Ù† TrueØŒ Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø­Ø°Ù
    """
    cutoff_date = datetime.now() - timedelta(days=days_to_keep)
    logs_dir = Path("logs")
    
    if not logs_dir.exists():
        print("Ù…Ø¬Ù„Ø¯ logs ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        return
    
    deleted_count = 0
    total_size = 0
    
    for log_type in ["prompts", "responses", "errors", "analytics"]:
        type_dir = logs_dir / log_type
        if not type_dir.exists():
            continue
        
        print(f"\nğŸ” ÙØ­Øµ {log_type}/")
        
        for log_file in type_dir.iterdir():
            if log_file.is_file():
                file_time = datetime.fromtimestamp(log_file.stat().st_mtime)
                if file_time < cutoff_date:
                    file_size = log_file.stat().st_size
                    total_size += file_size
                    deleted_count += 1
                    
                    if dry_run:
                        print(f"  [Ø³ÙŠØªÙ… Ø­Ø°Ù] {log_file.name} ({file_size / 1024:.2f} KB)")
                    else:
                        log_file.unlink()
                        print(f"  [ØªÙ… Ø­Ø°Ù] {log_file.name}")
    
    print(f"\n{'Ø³ÙŠØªÙ…' if dry_run else 'ØªÙ…'} Ø­Ø°Ù {deleted_count} Ù…Ù„Ù Ø¨Ø­Ø¬Ù… {total_size / 1024 / 1024:.2f} MB")
    
    if dry_run:
        print("\nâš ï¸  Ù‡Ø°Ø§ ÙØ­Øµ ØªØ¬Ø±ÙŠØ¨ÙŠ. Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø­Ø°Ù ÙØ¹Ù„ÙŠØ§Ù‹ØŒ Ø£Ø²Ù„ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„ dry_run")

# =============================================================================
# archive_logs.py - Ø£Ø±Ø´ÙØ© Logs
# =============================================================================

def archive_logs(month: str = None):
    """
    Ø£Ø±Ø´ÙØ© logs Ù„Ø´Ù‡Ø± Ù…Ø¹ÙŠÙ†
    
    Args:
        month: Ø§Ù„Ø´Ù‡Ø± Ø¨ØµÙŠØºØ© YYYYMM (Ù…Ø«Ø§Ù„: 202412)ØŒ Ø£Ùˆ None Ù„Ù„Ø´Ù‡Ø± Ø§Ù„Ù…Ø§Ø¶ÙŠ
    """
    if month is None:
        last_month = datetime.now().replace(day=1) - timedelta(days=1)
        month = last_month.strftime('%Y%m')
    
    logs_dir = Path("logs")
    archive_dir = Path("archives")
    archive_dir.mkdir(exist_ok=True)
    
    archive_name = f"logs_archive_{month}"
    temp_dir = Path(f"temp_{archive_name}")
    temp_dir.mkdir(exist_ok=True)
    
    print(f"ğŸ“¦ Ø£Ø±Ø´ÙØ© logs Ù„Ø´Ù‡Ø± {month}")
    
    file_count = 0
    
    for log_type in ["prompts", "responses", "errors", "analytics"]:
        type_dir = logs_dir / log_type
        if not type_dir.exists():
            continue
        
        temp_type_dir = temp_dir / log_type
        temp_type_dir.mkdir(exist_ok=True)
        
        for log_file in type_dir.iterdir():
            if log_file.is_file() and month in log_file.name:
                shutil.copy2(log_file, temp_type_dir / log_file.name)
                file_count += 1
    
    if file_count == 0:
        print(f"âš ï¸  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ù„Ø´Ù‡Ø± {month}")
        shutil.rmtree(temp_dir)
        return
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø±Ø´ÙŠÙ Ù…Ø¶ØºÙˆØ·
    archive_path = archive_dir / archive_name
    shutil.make_archive(str(archive_path), 'zip', temp_dir)
    shutil.rmtree(temp_dir)
    
    archive_size = (archive_path.with_suffix('.zip')).stat().st_size / 1024 / 1024
    
    print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø£Ø±Ø´ÙŠÙ: {archive_name}.zip")
    print(f"ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª: {file_count}")
    print(f"ğŸ’¾ Ø§Ù„Ø­Ø¬Ù…: {archive_size:.2f} MB")

# =============================================================================
# daily_report.py - ØªÙ‚Ø±ÙŠØ± ÙŠÙˆÙ…ÙŠ
# =============================================================================

def generate_daily_report(date_str: str = None) -> Dict[str, Any]:
    """
    Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± ÙŠÙˆÙ…ÙŠ Ø´Ø§Ù…Ù„
    
    Args:
        date_str: Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨ØµÙŠØºØ© YYYYMMDDØŒ Ø£Ùˆ None Ù„Ù„ÙŠÙˆÙ… Ø§Ù„Ø­Ø§Ù„ÙŠ
    
    Returns:
        Ù‚Ø§Ù…ÙˆØ³ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    """
    if date_str is None:
        date_str = datetime.now().strftime('%Y%m%d')
    
    analytics_file = Path(f"logs/analytics/analytics_{date_str}.jsonl")
    
    if not analytics_file.exists():
        print(f"âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù„ØªØ§Ø±ÙŠØ® {date_str}")
        return {}
    
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    analyses = []
    with open(analytics_file, 'r', encoding='utf-8') as f:
        analyses = [json.loads(line) for line in f]
    
    if not analyses:
        print("âš ï¸  Ø§Ù„Ù…Ù„Ù ÙØ§Ø±Øº")
        return {}
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    total = len(analyses)
    successful = sum(1 for a in analyses if a['success'])
    failed = total - successful
    
    successful_analyses = [a for a in analyses if a['success']]
    
    if successful > 0:
        avg_compliance = sum(a['compliance_ratio'] for a in successful_analyses) / successful
        avg_duration = sum(a['duration_seconds'] for a in successful_analyses) / successful
        min_compliance = min(a['compliance_ratio'] for a in successful_analyses)
        max_compliance = max(a['compliance_ratio'] for a in successful_analyses)
    else:
        avg_compliance = 0
        avg_duration = 0
        min_compliance = 0
        max_compliance = 0
    
    # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø³ÙŠØ§Ø³Ø©
    by_policy = defaultdict(lambda: {'count': 0, 'successful': 0, 'avg_compliance': 0})
    for a in analyses:
        policy = a['policy_type']
        by_policy[policy]['count'] += 1
        if a['success']:
            by_policy[policy]['successful'] += 1
            by_policy[policy]['avg_compliance'] += a['compliance_ratio']
    
    for policy in by_policy:
        if by_policy[policy]['successful'] > 0:
            by_policy[policy]['avg_compliance'] /= by_policy[policy]['successful']
    
    # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù…ØªØ§Ø¬Ø±
    shops = defaultdict(int)
    for a in analyses:
        shops[a['shop_name']] += 1
    top_shops = sorted(shops.items(), key=lambda x: x[1], reverse=True)[:5]
    
    # ØªÙˆØ²ÙŠØ¹ Ù†Ø³Ø¨ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„
    compliance_ranges = {
        '90-100%': 0,
        '80-89%': 0,
        '70-79%': 0,
        '60-69%': 0,
        '50-59%': 0,
        '<50%': 0
    }
    
    for a in successful_analyses:
        ratio = a['compliance_ratio']
        if ratio >= 90:
            compliance_ranges['90-100%'] += 1
        elif ratio >= 80:
            compliance_ranges['80-89%'] += 1
        elif ratio >= 70:
            compliance_ranges['70-79%'] += 1
        elif ratio >= 60:
            compliance_ranges['60-69%'] += 1
        elif ratio >= 50:
            compliance_ranges['50-59%'] += 1
        else:
            compliance_ranges['<50%'] += 1
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    print("=" * 80)
    print(f"ğŸ“Š ØªÙ‚Ø±ÙŠØ± ÙŠÙˆÙ…ÙŠ - {date_str}")
    print("=" * 80)
    print(f"\nğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©:")
    print(f"  Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª: {total}")
    print(f"  Ù†Ø§Ø¬Ø­: {successful} ({successful/total*100:.1f}%)")
    print(f"  ÙØ§Ø´Ù„: {failed} ({failed/total*100:.1f}%)")
    
    if successful > 0:
        print(f"\nğŸ“Š Ù†Ø³Ø¨ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„:")
        print(f"  Ù…ØªÙˆØ³Ø·: {avg_compliance:.1f}%")
        print(f"  Ø£Ø¯Ù†Ù‰: {min_compliance:.1f}%")
        print(f"  Ø£Ø¹Ù„Ù‰: {max_compliance:.1f}%")
        print(f"  Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø©: {avg_duration:.2f} Ø«Ø§Ù†ÙŠØ©")
        
        print(f"\nğŸ“‰ ØªÙˆØ²ÙŠØ¹ Ù†Ø³Ø¨ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„:")
        for range_name, count in compliance_ranges.items():
            if count > 0:
                print(f"  {range_name}: {count} ({count/successful*100:.1f}%)")
    
    print(f"\nğŸ“‹ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø³ÙŠØ§Ø³Ø©:")
    for policy_type, stats in by_policy.items():
        print(f"  {policy_type}:")
        print(f"    - Ø§Ù„Ø¹Ø¯Ø¯: {stats['count']}")
        print(f"    - Ø§Ù„Ù†Ø§Ø¬Ø­: {stats['successful']}")
        if stats['successful'] > 0:
            print(f"    - Ù…ØªÙˆØ³Ø· Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„: {stats['avg_compliance']:.1f}%")
    
    print(f"\nğŸª Ø£ÙƒØ«Ø± Ø§Ù„Ù…ØªØ§Ø¬Ø± ØªØ­Ù„ÙŠÙ„Ø§Ù‹:")
    for shop_name, count in top_shops[:5]:
        print(f"  {shop_name}: {count} ØªØ­Ù„ÙŠÙ„")
    
    print("=" * 80)
    
    return {
        'date': date_str,
        'total': total,
        'successful': successful,
        'failed': failed,
        'avg_compliance': avg_compliance,
        'avg_duration': avg_duration,
        'by_policy': dict(by_policy),
        'compliance_ranges': compliance_ranges,
        'top_shops': top_shops
    }

# =============================================================================
# analyze_errors.py - ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
# =============================================================================

def analyze_errors(days: int = 7):
    """
    ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙÙŠ Ø¢Ø®Ø± Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ø£ÙŠØ§Ù…
    
    Args:
        days: Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ù„Ù„ØªØ­Ù„ÙŠÙ„
    """
    cutoff_date = datetime.now() - timedelta(days=days)
    errors_dir = Path("logs/errors")
    
    if not errors_dir.exists():
        print("âŒ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        return
    
    error_files = [f for f in errors_dir.glob("error_*.json")]
    
    if not error_files:
        print("âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø®Ø·Ø§Ø¡!")
        return
    
    errors = []
    for error_file in error_files:
        file_time = datetime.fromtimestamp(error_file.stat().st_mtime)
        if file_time >= cutoff_date:
            with open(error_file, 'r', encoding='utf-8') as f:
                errors.append(json.load(f))
    
    if not errors:
        print(f"âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø®Ø·Ø§Ø¡ ÙÙŠ Ø¢Ø®Ø± {days} Ø£ÙŠØ§Ù…!")
        return
    
    # ØªØ­Ù„ÙŠÙ„ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
    error_types = Counter(e['error_type'] for e in errors)
    
    # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù…ØªØ§Ø¬Ø±
    by_shop = defaultdict(int)
    for e in errors:
        if e.get('shop_name'):
            by_shop[e['shop_name']] += 1
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
    print("=" * 80)
    print(f"ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ - Ø¢Ø®Ø± {days} Ø£ÙŠØ§Ù…")
    print("=" * 80)
    print(f"\nğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡: {len(errors)}")
    
    print(f"\nâŒ Ø£ÙƒØ«Ø± Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø´ÙŠÙˆØ¹Ø§Ù‹:")
    for error_type, count in error_types.most_common(10):
        print(f"  {error_type}: {count} Ù…Ø±Ø©")
    
    if by_shop:
        print(f"\nğŸª Ø§Ù„Ù…ØªØ§Ø¬Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ø®Ø·Ø§Ø¡:")
        for shop_name, count in sorted(by_shop.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"  {shop_name}: {count} Ø®Ø·Ø£")
    
    print("=" * 80)
    
    return {
        'total_errors': len(errors),
        'error_types': dict(error_types),
        'by_shop': dict(by_shop)
    }

# =============================================================================
# Main - ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨ØªØ§Øª
# =============================================================================

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:")
        print("  python scripts.py cleanup [days] [--dry-run]")
        print("  python scripts.py archive [YYYYMM]")
        print("  python scripts.py daily-report [YYYYMMDD]")
        print("  python scripts.py analyze-errors [days]")
        sys.exit(1)
    
    command = sys.argv[1]
    
    if command == "cleanup":
        days = int(sys.argv[2]) if len(sys.argv) > 2 else 30
        dry_run = '--dry-run' in sys.argv
        cleanup_old_logs(days, dry_run)
    
    elif command == "archive":
        month = sys.argv[2] if len(sys.argv) > 2 else None
        archive_logs(month)
    
    elif command == "daily-report":
        date_str = sys.argv[2] if len(sys.argv) > 2 else None
        generate_daily_report(date_str)
    
    elif command == "analyze-errors":
        days = int(sys.argv[2]) if len(sys.argv) > 2 else 7
        analyze_errors(days)
    
    else:
        print(f"âŒ Ø£Ù…Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ: {command}")
        sys.exit(1)
