"""
Secure Analysis API - Ø¨Ø¯ÙˆÙ† headers Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø§Ø³ØªØºÙ„Ø§Ù„
"""
import asyncio
import json
from fastapi import APIRouter, HTTPException, Request
from fastapi.responses import StreamingResponse
from typing import Optional
from datetime import datetime

from app.models import PolicyAnalysisRequest, ForceNewAnalysisRequest
from app.celery_app.tasks import analyze_policy_task
from celery.result import AsyncResult
from app.celery_app.celery import celery_app
from app.services.idempotency_service import idempotency_service
from app.logger import app_logger

router = APIRouter(prefix="/api", tags=["analysis"])


@router.post("/analyze")
async def analyze_policy_secure(
    request: PolicyAnalysisRequest,
    http_request: Request
):
    """
    âœ… Secure Analysis Endpoint with Complete Workflow
    
    Workflow:
    1. Generate idempotency_key from request body
    2. Check cache â†’ if found â†’ ask user
    3. Check pending tasks â†’ if found â†’ return existing task_id
    4. Check completed tasks â†’ if found â†’ retrieve & re-cache
    5. Submit new task only if needed
    
    - Ø¨Ø¯ÙˆÙ† headers Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø§Ø³ØªØºÙ„Ø§Ù„
    - ÙŠØ¹Ù…Ù„ idempotency key Ù…Ù† Ø§Ù„Ù€ body
    - checks ÙƒØ§Ù…Ù„Ø© Ù‚Ø¨Ù„ submit
    """
    client_ip = http_request.client.host
    app_logger.info(f"ğŸ“¨ New secure analysis request - Shop: {request.shop_name} - IP: {client_ip}")
    
    # 1. Generate idempotency key Ù…Ù† Ø§Ù„Ù€ request body (SHA256 hash)
    request_data = {
        "shop_name": request.shop_name,
        "shop_specialization": request.shop_specialization,
        "policy_type": request.policy_type.value,
        "policy_text": request.policy_text
    }
    
    idempotency_key = idempotency_service.generate_key_from_request(request_data)
    app_logger.info(f"ğŸ”‘ Generated idempotency key: {idempotency_key[:30]}...")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. CHECK CACHE FIRST (Highest Priority - Instant Return)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    app_logger.info(f"ğŸ” Step 1: Checking cache for key: {idempotency_key[:30]}...")
    cached_result = await idempotency_service.get_cached_result(idempotency_key)
    
    if cached_result:
        app_logger.info(f"âœ… Cache HIT - Asking user for decision")
        
        # ğŸ¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠÙ‚Ø±Ø±: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚Ø¯ÙŠÙ… Ø£Ùˆ ØªØ­Ù„ÙŠÙ„ Ø¬Ø¯ÙŠØ¯
        return {
            "status": "found_existing",
            "message": "ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø³Ø§Ø¨Ù‚ Ù„Ù†ÙØ³ Ø§Ù„Ø³ÙŠØ§Ø³Ø©",
            "result": cached_result,
            "idempotency_key": idempotency_key,
            "ask_user": True,  # â† Frontend ÙŠØ³Ø£Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            "options": {
                "use_existing": {
                    "label": "Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚",
                    "action": "use_cached",
                    "description": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¬Ø§Ù‡Ø² ÙˆÙ…Ø¬Ø§Ù†ÙŠ"
                },
                "create_new": {
                    "label": "Ø¥Ù†Ø´Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø¬Ø¯ÙŠØ¯",
                    "action": "force_new",
                    "endpoint": "/api/analyze/force-new",
                    "description": "ØªØ­Ù„ÙŠÙ„ Ø¬Ø¯ÙŠØ¯ (Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§)"
                }
            },
            "cached_at": cached_result.get('cache_timestamp', ''),
            "from_cache": True
        }
    
    app_logger.info(f"â„¹ï¸ Cache MISS - Proceeding to check for pending tasks...")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. CHECK PENDING/RUNNING TASKS (Avoid Duplicate Submissions)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    from celery.result import AsyncResult
    from app.celery_app.celery import celery_app
    
    app_logger.info(f"â³ Step 2: Checking for pending/running tasks...")
    existing_task = AsyncResult(idempotency_key, app=celery_app)
    
    # Check if task exists and is still running
    if existing_task.state in ['RECEIVED', 'STARTED', 'PROGRESS']:
        app_logger.info(
            f"â³ Found existing {existing_task.state} task - "
            f"Returning existing task_id: {idempotency_key[:30]}..."
        )
        
        # âœ… Return existing task_id (Ù…Ø´ Ù†Ø¹Ù…Ù„ task Ø¬Ø¯ÙŠØ¯!)
        return {
            "status": existing_task.state.lower(),
            "task_id": idempotency_key,
            "message": "ÙŠÙˆØ¬Ø¯ Ø·Ù„Ø¨ Ù…Ø·Ø§Ø¨Ù‚ Ù‚ÙŠØ¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©",
            "idempotency_key": idempotency_key,
            "check_status_url": f"/api/task/{idempotency_key}",
            "from_cache": False,
            "note": "ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø·Ù„Ø¨ Ù…Ø·Ø§Ø¨Ù‚ Ù‚ÙŠØ¯ Ø§Ù„ØªÙ†ÙÙŠØ° - Ù„Ù† ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø·Ù„Ø¨ Ø¬Ø¯ÙŠØ¯"
        }
    
    app_logger.info(f"â„¹ï¸ No pending tasks found - Checking completed tasks...")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. CHECK COMPLETED TASKS (Retrieve from Celery Backend)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if existing_task.state == 'SUCCESS':
        app_logger.warning(
            f"ğŸ’¾ Step 3: Task was successful but result not in cache - "
            f"Fetching from Celery result backend"
        )
        
        try:
            # Quick fetch from Celery backend (timeout 5s)
            task_result = existing_task.get(timeout=5)
            
            if task_result and isinstance(task_result, dict):
                result_data = task_result.get('result')
                
                if result_data:
                    # âœ… Re-cache the result for next time
                    await idempotency_service.store_result(idempotency_key, result_data)
                    
                    app_logger.info(f"âœ… Retrieved result from Celery backend and re-cached")
                    
                    # Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø²ÙŠ Ù„Ùˆ ÙƒØ§Ù† ÙÙŠ cache)
                    return {
                        "status": "found_existing",
                        "message": "ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø³Ø§Ø¨Ù‚ Ù„Ù†ÙØ³ Ø§Ù„Ø³ÙŠØ§Ø³Ø©",
                        "result": result_data,
                        "idempotency_key": idempotency_key,
                        "ask_user": True,
                        "options": {
                            "use_existing": {
                                "label": "Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚",
                                "action": "use_cached",
                                "description": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¬Ø§Ù‡Ø² ÙˆÙ…Ø¬Ø§Ù†ÙŠ"
                            },
                            "create_new": {
                                "label": "Ø¥Ù†Ø´Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø¬Ø¯ÙŠØ¯",
                                "action": "force_new",
                                "endpoint": "/api/analyze/force-new",
                                "description": "ØªØ­Ù„ÙŠÙ„ Ø¬Ø¯ÙŠØ¯ (Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§)"
                            }
                        },
                        "from_cache": True,
                        "note": "ØªÙ… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù…Ù† Celery backend"
                    }
        except Exception as e:
            app_logger.warning(
                f"âš ï¸ Failed to retrieve result from Celery backend: {str(e)} - "
                f"Will create new task"
            )
            # Continue to create new task
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. SUBMIT NEW TASK (Only if no cache, no pending, no completed)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    app_logger.info(f"ğŸš€ Step 4: No existing data found - Submitting NEW task to Celery")
    
    # Use idempotency_key as task_id for future deduplication
    task = analyze_policy_task.apply_async(
        args=[
            request.shop_name,
            request.shop_specialization,
            request.policy_type.value,
            request.policy_text,
            idempotency_key,
            False  # force_refresh = False Ø¯Ø§Ø¦Ù…Ù‹Ø§ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù€ endpoint
        ],
        task_id=idempotency_key  # â† Important: Use idempotency_key for deduplication
    )
    
    app_logger.info(f"âœ… New task submitted - ID: {task.id}")
    
    return {
        "status": "pending",
        "task_id": task.id,
        "message": "ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©",
        "idempotency_key": idempotency_key,
        "check_status_url": f"/api/task/{task.id}",
        "from_cache": False
    }


@router.post("/analyze/force-new")
async def force_new_analysis(
    request: ForceNewAnalysisRequest,
    http_request: Request
):
    """
    ğŸ”’ Force New Analysis - Ø¨Ø­Ù…Ø§ÙŠØ© Ù…Ù† Ø§Ù„Ø§Ø³ØªØºÙ„Ø§Ù„
    
    Security Features:
    - ÙŠØ­ØªØ§Ø¬ idempotency_key ØµØ§Ù„Ø­ (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ù€ request)
    - Rate limited Ø¨Ø´Ø¯Ø© (3 requests/hour per IP)
    - ÙŠØªØªØ¨Ø¹ ÙƒÙ„ IP ÙˆÙƒÙ„ Ù…Ø­Ø§ÙˆÙ„Ø©
    - ÙŠØ³ØªØ®Ø¯Ù… Pydantic model Ù…Ø­ØªØ±Ù… Ù…Ø¹ validation ÙƒØ§Ù…Ù„
    - ÙŠØ­Ø°Ù Ø§Ù„Ù€ cache Ø§Ù„Ù‚Ø¯ÙŠÙ… Ù‚Ø¨Ù„ Ø¥Ù†Ø´Ø§Ø¡ task Ø¬Ø¯ÙŠØ¯
    
    Workflow:
    1. Check rate limit (3/hour)
    2. Validate idempotency_key matches request
    3. Delete old cache
    4. Cancel any pending tasks (optional but recommended)
    5. Create new unique task
    """
    client_ip = http_request.client.host
    
    app_logger.info(
        f"ğŸ”„ Force refresh request - Shop: {request.shop_name} - IP: {client_ip} - "
        f"Key: {request.idempotency_key[:30]}..."
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. CHECK RATE LIMIT (Ù…Ø´Ø¯Ø¯ Ø¬Ø¯Ù‹Ø§ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù€ endpoint)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    from app.safeguards import rate_limiter
    
    is_limited, reason = rate_limiter.is_rate_limited(
        identifier=f"force_refresh:{client_ip}",
        max_requests=3,  # 3 Ø·Ù„Ø¨Ø§Øª force refresh ÙÙ‚Ø·
        window_seconds=3600,  # ÙÙŠ Ø§Ù„Ø³Ø§Ø¹Ø©
        block_duration_minutes=60  # Ø­Ø¸Ø± Ø³Ø§Ø¹Ø©
    )
    
    if is_limited:
        app_logger.warning(
            f"ğŸš« Rate limit exceeded for force refresh - IP: {client_ip} - {reason}"
        )
        raise HTTPException(
            status_code=429,
            detail={
                "error": "ØªÙ… ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­",
                "message": reason,
                "retry_after": 3600,
                "remaining_attempts": 0
            }
        )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. VALIDATE IDEMPOTENCY KEY (ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ·Ø§Ø¨Ù‚ Ø§Ù„Ù€ request)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    request_data = {
        "shop_name": request.shop_name,
        "shop_specialization": request.shop_specialization,
        "policy_type": request.policy_type.value,
        "policy_text": request.policy_text
    }
    
    expected_key = idempotency_service.generate_key_from_request(request_data)
    
    if request.idempotency_key != expected_key:
        app_logger.error(
            f"âŒ Invalid idempotency key - Expected: {expected_key[:30]}..., "
            f"Got: {request.idempotency_key[:30]}... - IP: {client_ip}"
        )
        
        # Track suspicious behavior
        # rate_limiter.track_suspicious_activity(
        #     identifier=f"invalid_key:{client_ip}",
        #     reason="Invalid idempotency key in force-new"
        # )
        
        raise HTTPException(
            status_code=400,
            detail={
                "error": "Invalid idempotency key",
                "message": "Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ØºÙŠØ± ØµØ§Ù„Ø­ - ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø±Ø³Ø§Ù„ Ù†ÙØ³ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
                "hint": "ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ·Ø§Ø¨Ù‚ Ø§Ù„Ù€ idempotency_key Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙØ±Ø³Ù„Ø©"
            }
        )
    
    app_logger.info(f"âœ… Idempotency key validated successfully")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. DELETE OLD CACHE (ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    app_logger.info(f"ğŸ—‘ï¸ Deleting old cache for key: {request.idempotency_key[:30]}...")
    
    deletion_result = await idempotency_service.delete_cached_result(request.idempotency_key)
    
    if deletion_result:
        app_logger.info(f"âœ… Old cache deleted successfully")
    else:
        app_logger.info(f"â„¹ï¸ No cache found to delete (might be first analysis)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. CANCEL PENDING TASKS (Optional - Ù…Ù†Ø¹ ØªØ¹Ø§Ø±Ø¶ Tasks)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    from celery.result import AsyncResult
    from app.celery_app.celery import celery_app
    
    # Check if there's a pending task with the same idempotency_key
    existing_task = AsyncResult(request.idempotency_key, app=celery_app)
    
    if existing_task.state in ['STARTED', 'PROGRESS']:
        app_logger.warning(
            f"âš ï¸ Found existing {existing_task.state} task - "
            f"Attempting to revoke it before creating new one"
        )
        
        try:
            # Revoke the old task (terminate=True to kill it immediately)
            existing_task.revoke(terminate=True)
            app_logger.info(f"âœ… Old task revoked successfully")
        except Exception as e:
            app_logger.warning(f"âš ï¸ Failed to revoke old task: {str(e)}")
            # Continue anyway - the new task will take priority
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. CREATE NEW UNIQUE TASK (ØªØ¬Ù†Ø¨ Celery Deduplication)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    import time
    
    # Generate unique task_id (millisecond precision)
    unique_task_id = f"{request.idempotency_key}_refresh_{int(time.time() * 1000)}"
    
    app_logger.info(f"ğŸš€ Creating NEW task with unique ID: {unique_task_id[:40]}...")
    
    task = analyze_policy_task.apply_async(
        args=[
            request.shop_name,
            request.shop_specialization,
            request.policy_type.value,
            request.policy_text,
            request.idempotency_key,  # Original key for caching
            True  # force_refresh = True
        ],
        task_id=unique_task_id,  # Unique ID to bypass Celery cache
        priority=5  # Higher priority for force refresh (0-10, default is 6)
    )
    
    app_logger.info(
        f"âœ… Force refresh task submitted successfully - "
        f"Task ID: {task.id} - Shop: {request.shop_name}"
    )
    
    # Track successful force refresh
    # rate_limiter.track_successful_request(
    #     identifier=f"force_refresh:{client_ip}",
    #     metadata={
    #         "shop_name": request.shop_name,
    #         "policy_type": request.policy_type.value,
    #         "task_id": task.id
    #     }
    # )
    
    return {
        "status": "pending",
        "task_id": task.id,
        "message": "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­",
        "idempotency_key": request.idempotency_key,
        "check_status_url": f"/api/task/{task.id}",
        "force_refresh": True,
        "from_cache": False,
        "estimated_time": "1-2 Ø¯Ù‚ÙŠÙ‚Ø©",
        "note": "Ø³ÙŠØªÙ… Ø­Ø°Ù Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø¯ÙŠÙ… ÙˆØ§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡ Ø¨Ø§Ù„Ø¬Ø¯ÙŠØ¯"
    }


@router.get("/task/{task_id}")
async def get_task_status(task_id: str):
    """
    Get Task Status and Result
    """
    app_logger.debug(f"ğŸ“Š Status check for task: {task_id[:30]}...")
    
    result = AsyncResult(task_id, app=celery_app)
    
    if result.ready():
        if result.successful():
            task_result = result.get()
            
            app_logger.info(f"âœ… Task {task_id[:30]} completed successfully")
            
            return {
                "status": "completed",
                "task_id": task_id,
                "result": task_result.get('result') if task_result.get('success') else None,
                "from_cache": task_result.get('from_cache', False),
                "success": task_result.get('success', True),
                "error": task_result.get('error'),
                "completed_at": datetime.utcnow().isoformat()
            }
        else:
            app_logger.error(f"âŒ Task {task_id[:30]} failed")
            
            return {
                "status": "failed",
                "task_id": task_id,
                "error": str(result.info),
                "failed_at": datetime.utcnow().isoformat()
            }
    
    elif result.state == 'PENDING':
        app_logger.debug(f"â³ Task {task_id[:30]} pending...")
        
        return {
            "status": "pending",
            "task_id": task_id,
            "message": "ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©..."
        }
    
    elif result.state == 'STARTED':
        app_logger.debug(f"ğŸ”„ Task {task_id[:30]} started")
        
        return {
            "status": "processing",
            "task_id": task_id,
            "progress": result.info,
            "message": "Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©..."
        }
    
    elif result.state == 'PROGRESS':
        app_logger.debug(f"ğŸ”„ Task {task_id[:30]} in progress")
        
        return {
            "status": "processing",
            "task_id": task_id,
            "progress": result.info,
            "message": result.info.get('status', 'Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©...')
        }
    
    else:
        return {
            "status": result.state.lower(),
            "task_id": task_id,
            "info": str(result.info)
        }


@router.get("/task/{task_id}/stream")
async def stream_task_status(task_id: str, request: Request):
    """
    Streams task status updates using Server-Sent Events (SSE).
    """
    
    task = AsyncResult(task_id, app=celery_app)
    if task.state == 'PENDING' and not task.result:
        pass

    async def event_generator():
        try:
            while True:
                if await request.is_disconnected():
                    break

                result = AsyncResult(task_id, app=celery_app)
                
                data = {
                    "task_id": task_id,
                    "status": result.status.lower(),
                    "progress": {},
                    "timestamp": datetime.utcnow().isoformat()
                }

                if result.state == 'SUCCESS':
                    data["status"] = "completed"
                    data["result"] = result.get()
                    yield f"data: {json.dumps(data)}\n\n"
                    break
                
                elif result.state == 'FAILURE':
                    data["status"] = "failed"
                    data["error"] = str(result.info)
                    yield f"data: {json.dumps(data)}\n\n"
                    break
                
                elif result.state in ['STARTED', 'PROGRESS']:
                    data["status"] = "processing"
                    data["progress"] = result.info if isinstance(result.info, dict) else {}
                    yield f"data: {json.dumps(data)}\n\n"
                
                else:
                     data["status"] = "pending"
                     yield f"data: {json.dumps(data)}\n\n"

                await asyncio.sleep(2)

        except Exception as e:
            app_logger.error(f"Stream error for {task_id}: {e}")
            yield f"data: {json.dumps({'status': 'error', 'message': str(e)})}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@router.delete("/task/{task_id}")
async def cancel_task(task_id: str):
    """Cancel a Running Task"""
    app_logger.info(f"ğŸ›‘ Cancel request for task: {task_id[:30]}...")
    
    result = AsyncResult(task_id, app=celery_app)
    
    if result.state in ['PENDING', 'STARTED', 'PROGRESS']:
        result.revoke(terminate=True)
        app_logger.info(f"âœ… Task {task_id[:30]} cancelled")
        
        return {
            "status": "cancelled",
            "task_id": task_id,
            "message": "ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø©"
        }
    else:
        raise HTTPException(
            status_code=400,
            detail=f"Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙŠ Ø§Ù„Ø­Ø§Ù„Ø©: {result.state}"
        )


@router.get("/tasks/active")
async def get_active_tasks():
    """Get All Active Tasks"""
    inspector = celery_app.control.inspect()
    
    active = inspector.active()
    scheduled = inspector.scheduled()
    reserved = inspector.reserved()
    
    return {
        "active": active or {},
        "scheduled": scheduled or {},
        "reserved": reserved or {},
        "timestamp": datetime.utcnow().isoformat()
    }