# ============================================
# File: app/services/openai/light_model.py
# ============================================
"""
Light Model Client - Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø¨Ø³ÙŠØ·Ø© (Stage 1)
"""
from typing import Dict, Any
from app.config import get_settings
from app.safeguards import openai_circuit_breaker
from app.prompts.system_prompt import SYSTEM_PROMPT
from .base_client import BaseOpenAIClient

settings = get_settings()

class LightModelClient(BaseOpenAIClient):
    """
    ğŸª¶ Light Model - Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø³Ø±ÙŠØ¹Ø© ÙˆØ§Ù„Ø¨Ø³ÙŠØ·Ø©
    ÙŠØ³ØªØ®Ø¯Ù… ÙÙŠ Stage 1: Policy Match Check
    """
    def __init__(self):
        super().__init__()
        self.model = settings.openai_light_model
        self.temperature = settings.openai_light_temperature
        self.max_tokens = settings.openai_light_max_tokens
    
    async def call(self, prompt: str, json_response: bool = True) -> Dict[str, Any]:
        """
        Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Light Model
        
        Args:
            prompt: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
            json_response: Ù‡Ù„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© JSONØŸ
        """
        import time
        start_time = time.time()
        
        self.logger.debug(f"ğŸª¶ Calling LIGHT model: {self.model}")
        
        # 1. ÙØ­Øµ Ø§Ù„Ø­Ø¯ÙˆØ¯
        self.check_usage_limits()
        
        # 2. ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù€ tokens
        self.estimate_and_validate_tokens(prompt)
        
        try:
            # 3. Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API
            @openai_circuit_breaker.call
            async def make_api_call():
                return await self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=self.temperature,
                    max_tokens=min(self.max_tokens, self.safeguard.max_tokens_per_request),
                    response_format={"type": "json_object"} if json_response else {"type": "text"}
                )
            
            response = await self.safeguard.safe_api_call(make_api_call)
            
            # 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©
            duration = time.time() - start_time
            content = response.choices[0].message.content
            usage = response.usage
            
            self.safeguard.increment_usage(usage.total_tokens)
            
            self.logger.info(
                f"âœ… LIGHT model success - Duration: {duration:.2f}s - "
                f"Tokens: {usage.total_tokens}"
            )
            
            # 5. Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø©
            if json_response:
                return self.parse_json_response(content)
            return {"content": content}
            
        except Exception as e:
            duration = time.time() - start_time
            self.log_api_error(e, duration, "LIGHT")
            raise

