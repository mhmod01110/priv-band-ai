import tiktoken
from openai import OpenAI
from typing import Dict, List
import json

class TokenTracker:
    def __init__(self, model="gpt-4"):
        self.model = model
        self.client = OpenAI()
        try:
            self.encoding = tiktoken.encoding_for_model(model)
        except KeyError:
            self.encoding = tiktoken.get_encoding("cl100k_base")
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.stats = {
            "total_requests": 0,
            "total_input_tokens": 0,
            "total_output_tokens": 0,
            "total_tokens": 0,
            "requests_history": []
        }
    
    def count_tokens(self, text: str) -> int:
        """Ø­Ø³Ø§Ø¨ tokens Ù„Ù†Øµ ÙˆØ§Ø­Ø¯"""
        return len(self.encoding.encode(text))
    
    def count_message_tokens(self, messages: List[Dict]) -> int:
        """Ø­Ø³Ø§Ø¨ tokens Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© messages"""
        tokens_per_message = 3
        tokens_per_name = 1
        
        num_tokens = 0
        for message in messages:
            num_tokens += tokens_per_message
            for key, value in message.items():
                num_tokens += len(self.encoding.encode(str(value)))
                if key == "name":
                    num_tokens += tokens_per_name
        
        num_tokens += 3
        return num_tokens
    
    def chat_completion(self, messages: List[Dict], **kwargs) -> Dict:
        """
        Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API Ù…Ø¹ ØªØªØ¨Ø¹ Ø§Ù„Ù€ tokens
        """
        # Ø­Ø³Ø§Ø¨ input tokens
        input_tokens = self.count_message_tokens(messages)
        
        # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            **kwargs
        )
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ usage Ù…Ù† Ø§Ù„Ù€ response
        usage = response.usage
        output_tokens = usage.completion_tokens
        total_tokens = usage.total_tokens
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        request_info = {
            "request_number": self.stats["total_requests"] + 1,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "total_tokens": total_tokens,
            "prompt_preview": messages[-1]["content"][:100] + "...",
        }
        
        self.stats["total_requests"] += 1
        self.stats["total_input_tokens"] += input_tokens
        self.stats["total_output_tokens"] += output_tokens
        self.stats["total_tokens"] += total_tokens
        self.stats["requests_history"].append(request_info)
        
        # Ø·Ø¨Ø§Ø¹Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù€ request
        self.print_request_info(request_info)
        
        return response
    
    def print_request_info(self, info: Dict):
        """Ø·Ø¨Ø§Ø¹Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù€ request"""
        print("\n" + "="*60)
        print(f"ğŸ“Š Request #{info['request_number']}")
        print("-"*60)
        print(f"ğŸ“¥ Input Tokens:  {info['input_tokens']:,}")
        print(f"ğŸ“¤ Output Tokens: {info['output_tokens']:,}")
        print(f"ğŸ“¦ Total Tokens:  {info['total_tokens']:,}")
        print("="*60 + "\n")
    
    def print_summary(self):
        """Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒÙ„ÙŠ"""
        print("\n" + "="*60)
        print("ğŸ“ˆ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…")
        print("="*60)
        print(f"ğŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù€ Requests:        {self.stats['total_requests']}")
        print(f"ğŸ“¥ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Input Tokens:   {self.stats['total_input_tokens']:,}")
        print(f"ğŸ“¤ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Output Tokens:  {self.stats['total_output_tokens']:,}")
        print(f"ğŸ“¦ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Total Tokens:   {self.stats['total_tokens']:,}")
        print("="*60)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠØ© (GPT-4)
        # $0.03 per 1K input tokens, $0.06 per 1K output tokens
        input_cost = (self.stats['total_input_tokens'] / 1000) * 0.03
        output_cost = (self.stats['total_output_tokens'] / 1000) * 0.06
        total_cost = input_cost + output_cost
        
        print(f"\nğŸ’° Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠØ©:")
        print(f"   Input:  ${input_cost:.4f}")
        print(f"   Output: ${output_cost:.4f}")
        print(f"   Total:  ${total_cost:.4f}")
        print("="*60 + "\n")
    
    def export_stats(self, filename="token_stats.json"):
        """ØªØµØ¯ÙŠØ± Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù„Ù…Ù„Ù JSON"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.stats, f, ensure_ascii=False, indent=2)
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙÙŠ: {filename}")

# Ù…Ø«Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
tracker = TokenTracker(model="gpt-4")

messages = [
    {"role": "system", "content": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ"},
    {"role": "user", "content": "Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ø³Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©..."}
]

# Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API
response = tracker.chat_completion(
    messages=messages,
    temperature=0.3,
    max_tokens=2000
)

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†ØªÙŠØ¬Ø©
result = response.choices[0].message.content
print(result)

# Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù…Ù„Ø®Øµ
tracker.print_summary()

# Ø­ÙØ¸ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
tracker.export_stats()