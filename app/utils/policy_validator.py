"""
Policy Enhanced Validator
Rule-based policy matching to save AI tokens
"""
import re
from typing import Dict, List, Tuple, Optional
from app.logger import app_logger


class PolicyValidator:
    """
    Pre-AI validation and rule-based policy matching
    Saves tokens by catching obvious matches/mismatches
    """
    
    # Policy type keywords and patterns
    POLICY_RULES = {
        'Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ùˆ Ø§Ù„Ø§Ø³ØªØ¨Ø¯Ø§Ù„': {
            'required_keywords': [
                'Ø¥Ø±Ø¬Ø§Ø¹', 'Ø§Ø³ØªØ±Ø¬Ø§Ø¹', 'Ø§Ø³ØªØ¨Ø¯Ø§Ù„', 'Ø¥Ø¹Ø§Ø¯Ø©', 'Ø±Ø¯'
            ],
            'strong_indicators': [
                '7 Ø£ÙŠØ§Ù…', 'Ø³Ø¨Ø¹Ø© Ø£ÙŠØ§Ù…', 'Ø£Ø³Ø¨ÙˆØ¹', 'ÙØ³Ø® Ø§Ù„Ø¹Ù‚Ø¯', 
                'Ø§Ø³ØªØ±Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¨Ù„Øº', 'Ø§Ø³ØªØ±Ø¯Ø§Ø¯ Ø§Ù„Ù‚ÙŠÙ…Ø©'
            ],
            'moderate_indicators': [
                'Ù…Ù†ØªØ¬', 'Ø¨Ø¶Ø§Ø¹Ø©', 'Ø³Ù„Ø¹Ø©', 'ÙØ§ØªÙˆØ±Ø©', 'Ø¹ÙŠØ¨', 
                'Ø­Ø§Ù„Ø© Ø£ØµÙ„ÙŠØ©', 'ØªØºÙ„ÙŠÙ'
            ],
            'forbidden_topics': [
                'Ø®ØµÙˆØµÙŠØ©', 'Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø®ØµÙŠØ©', 'Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…',
                'Ø´Ø­Ù†', 'ØªÙˆØµÙŠÙ„', 'Ù†Ù‚Ù„'
            ],
            'minimum_length': 100,
            'expected_sections': [
                'Ù…Ø¯Ø©', 'Ø´Ø±ÙˆØ·', 'Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª'
            ]
        },
        
        'Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø­Ø³Ø§Ø¨ Ùˆ Ø§Ù„Ø®ØµÙˆØµÙŠØ©': {
            'required_keywords': [
                'Ø®ØµÙˆØµÙŠØ©', 'Ø¨ÙŠØ§Ù†Ø§Øª', 'Ù…Ø¹Ù„ÙˆÙ…Ø§Øª', 'Ø­Ø³Ø§Ø¨'
            ],
            'strong_indicators': [
                'Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø®ØµÙŠØ©', 'Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…', 'Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª',
                'Ø­Ø°Ù Ø§Ù„Ø­Ø³Ø§Ø¨', 'ØªØ´ÙÙŠØ±', 'Ø£Ù…Ø§Ù†'
            ],
            'moderate_indicators': [
                'Ø§Ø³Ù…', 'Ø¹Ù†ÙˆØ§Ù†', 'Ù‡Ø§ØªÙ', 'Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ',
                'ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ±', 'ØªØ³Ø¬ÙŠÙ„', 'Ù…Ø´Ø§Ø±ÙƒØ©'
            ],
            'forbidden_topics': [
                'Ø¥Ø±Ø¬Ø§Ø¹', 'Ø§Ø³ØªØ±Ø¬Ø§Ø¹', 'Ø§Ø³ØªØ¨Ø¯Ø§Ù„',
                'Ø´Ø­Ù†', 'ØªÙˆØµÙŠÙ„'
            ],
            'minimum_length': 150,
            'expected_sections': [
                'Ø¬Ù…Ø¹', 'Ø§Ø³ØªØ®Ø¯Ø§Ù…', 'Ø­Ù…Ø§ÙŠØ©', 'Ø­Ù‚ÙˆÙ‚'
            ]
        },
        
        'Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ø´Ø­Ù† Ùˆ Ø§Ù„ØªÙˆØµÙŠÙ„': {
            'required_keywords': [
                'Ø´Ø­Ù†', 'ØªÙˆØµÙŠÙ„', 'Ù†Ù‚Ù„', 'Ø¥Ø±Ø³Ø§Ù„'
            ],
            'strong_indicators': [
                'Ù…Ø¯Ø© Ø§Ù„ØªÙˆØµÙŠÙ„', 'Ø±Ø³ÙˆÙ… Ø§Ù„Ø´Ø­Ù†', 'Ø´Ø±ÙƒØ© Ø§Ù„Ø´Ø­Ù†',
                '15 ÙŠÙˆÙ…Ø§Ù‹', 'Ø®Ù…Ø³Ø© Ø¹Ø´Ø± ÙŠÙˆÙ…Ø§Ù‹', 'ØªØ£Ø®ÙŠØ±'
            ],
            'moderate_indicators': [
                'Ø·Ù„Ø¨', 'Ø¹Ù†ÙˆØ§Ù†', 'Ù…Ù†Ø·Ù‚Ø©', 'Ù…Ø¬Ø§Ù†ÙŠ',
                'ØªØªØ¨Ø¹', 'Ø§Ø³ØªÙ„Ø§Ù…', 'ØªØ³Ù„ÙŠÙ…'
            ],
            'forbidden_topics': [
                'Ø¥Ø±Ø¬Ø§Ø¹', 'Ø§Ø³ØªØ±Ø¬Ø§Ø¹', 'Ø§Ø³ØªØ¨Ø¯Ø§Ù„',
                'Ø®ØµÙˆØµÙŠØ©', 'Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø®ØµÙŠØ©'
            ],
            'minimum_length': 100,
            'expected_sections': [
                'Ù…Ø¯Ø©', 'ØªÙƒÙ„ÙØ©', 'Ù…Ù†Ø§Ø·Ù‚'
            ]
        }
    }
    
    def __init__(self):
        self.confidence_thresholds = {
            'high': 0.85,      # Skip AI, direct accept
            'medium': 0.60,     # Use AI
            'low': 0.40,        # Use AI
            'very_low': 0.20   # Skip AI, direct reject
        }
    
    def validate_and_score(
        self,
        policy_text: str,
        policy_type: str
    ) -> Dict:
        """
        Main validation method
        
        Returns:
            {
                'confidence': float (0-1),
                'is_matched': bool,
                'reason': str,
                'skip_ai': bool,
                'details': dict
            }
        """
        app_logger.info(f"ğŸ” Policy Validator - Checking: {policy_type}")
        
        # Get rules for this policy type
        rules = self.POLICY_RULES.get(policy_type)
        if not rules:
            app_logger.warning(f"No rules found for policy type: {policy_type}")
            return {
                'confidence': 0.5,
                'is_matched': None,
                'reason': 'Ù†ÙˆØ¹ Ø³ÙŠØ§Ø³Ø© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ',
                'skip_ai': False,
                'details': {}
            }
        
        # Clean text
        text_lower = policy_text.lower().strip()
        
        # Calculate scores
        scores = self._calculate_scores(text_lower, rules)
        
        # Make decision
        decision = self._make_decision(scores, rules)
        
        app_logger.info(
            f"ğŸ“Š Validation result - Confidence: {decision['confidence']:.2%}, "
            f"Skip AI: {decision['skip_ai']}"
        )
        
        return decision
    
    def _calculate_scores(self, text: str, rules: Dict) -> Dict:
        """
        Calculate various matching scores
        """
        scores = {
            'required_keywords': 0,
            'strong_indicators': 0,
            'moderate_indicators': 0,
            'forbidden_topics': 0,
            'length_check': 0,
            'section_check': 0
        }
        
        # 1. Required keywords (must have at least one)
        required = rules['required_keywords']
        found_required = sum(1 for kw in required if kw in text)
        scores['required_keywords'] = found_required / len(required) if required else 0
        
        # 2. Strong indicators (good to have)
        strong = rules['strong_indicators']
        found_strong = sum(1 for kw in strong if kw in text)
        scores['strong_indicators'] = found_strong / len(strong) if strong else 0
        
        # 3. Moderate indicators
        moderate = rules['moderate_indicators']
        found_moderate = sum(1 for kw in moderate if kw in text)
        scores['moderate_indicators'] = found_moderate / len(moderate) if moderate else 0
        
        # 4. Forbidden topics (should NOT be present)
        forbidden = rules['forbidden_topics']
        found_forbidden = sum(1 for kw in forbidden if kw in text)
        scores['forbidden_topics'] = found_forbidden / len(forbidden) if forbidden else 0
        
        # 5. Length check
        min_length = rules['minimum_length']
        scores['length_check'] = min(1.0, len(text) / min_length)
        
        # 6. Expected sections
        expected_sections = rules['expected_sections']
        found_sections = sum(1 for section in expected_sections if section in text)
        scores['section_check'] = found_sections / len(expected_sections) if expected_sections else 0
        
        return scores
    
    def _make_decision(self, scores: Dict, rules: Dict) -> Dict:
        """
        Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø³Ø¨
        """
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù…Ø±Ø¬Ø­Ø©
        if scores['required_keywords'] == 0:
            confidence = 0.1 + (scores['moderate_indicators'] * 0.1)
            return {
                'confidence': confidence,
                'is_matched': False,
                'reason': 'Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù†Øµ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©',
                'skip_ai': confidence < self.confidence_thresholds['very_low'],
                'details': scores
            }
        
        # ÙØ­Øµ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø©
        if scores['forbidden_topics'] > 0.5:
            confidence = 0.2
            return {
                'confidence': confidence,
                'is_matched': False,
                'reason': 'Ø§Ù„Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù„Ø§ ØªØªØ¹Ù„Ù‚ Ø¨Ù†ÙˆØ¹ Ø§Ù„Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯',
                'skip_ai': True,
                'details': scores
            }
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        weights = {
            'required_keywords': 0.35,
            'strong_indicators': 0.25,
            'moderate_indicators': 0.15,
            'length_check': 0.10,
            'section_check': 0.15
        }
        
        confidence = sum(
            scores.get(key, 0) * weight
            for key, weight in weights.items()
        )
        
        # Ø¹Ù‚ÙˆØ¨Ø© Ù„Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø©
        confidence *= (1 - scores['forbidden_topics'] * 0.5)
        
        # âœ… Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„ØµØ­ÙŠØ­ - Ù…Ø­Ø§Ø°ÙŠ Ù…Ø¹ Stage 1 (30-70%)
        skip_ai = False
        is_matched = None
        reason = ''
        
        # Ø§Ù„Ø­Ø§Ù„Ø© 1: Ù†Ø³Ø¨Ø© Ø¹Ø§Ù„ÙŠØ© (>= 70%)
        if confidence >= 0.70:
            is_matched = True  # âœ… Ù…ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡Ø§ matched
            
            if confidence >= 0.85:
                # ÙˆØ§Ø«Ù‚ Ø¬Ø¯Ù‹Ø§ - Ù†ØªØ®Ø·Ù‰ AI ØªÙ…Ø§Ù…Ù‹Ø§
                skip_ai = True
                reason = 'ØªØ·Ø§Ø¨Ù‚ Ù‚ÙˆÙŠ - Ø§Ù„Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©'
            else:
                # ÙˆØ§Ø«Ù‚ Ø¨Ø³ Ù…Ø´ Ø¬Ø¯Ù‹Ø§ - Ù‡Ù†Ø£ÙƒØ¯ ÙÙŠ Stage 3 Ø¨Ø¯ÙˆÙ† Stage 1
                skip_ai = False
                reason = 'ØªØ·Ø§Ø¨Ù‚ Ø¬ÙŠØ¯ - ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ø¨Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø­Ù„ÙŠØ©'
        
        # Ø§Ù„Ø­Ø§Ù„Ø© 2: Ù†Ø³Ø¨Ø© Ù…Ù†Ø®ÙØ¶Ø© (<= 30%)
        elif confidence <= 0.30:
            is_matched = False  # âœ… Ù…ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡Ø§ Ù…Ø´ matched
            
            if confidence <= 0.20:
                # ÙˆØ§Ø«Ù‚ Ø¬Ø¯Ù‹Ø§ Ø¥Ù†Ù‡Ø§ ØºÙ„Ø· - Ù†ØªØ®Ø·Ù‰ AI ØªÙ…Ø§Ù…Ù‹Ø§
                skip_ai = True
                reason = 'Ø¹Ø¯Ù… ØªØ·Ø§Ø¨Ù‚ ÙˆØ§Ø¶Ø­ - Ø§Ù„Ù†Øµ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙƒØ§ÙÙŠØ©'
            else:
                # Ø´Ø¨Ù‡ Ù…ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡Ø§ ØºÙ„Ø· - Ù‡Ù†Ø£ÙƒØ¯ ÙÙŠ Stage 3 Ø¨Ø¯ÙˆÙ† Stage 1
                skip_ai = False
                reason = 'ØªØ·Ø§Ø¨Ù‚ Ø¶Ø¹ÙŠÙ - ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ø¨Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø­Ù„ÙŠØ©'
        
        # Ø§Ù„Ø­Ø§Ù„Ø© 3: Ù†Ø³Ø¨Ø© ØºØ§Ù…Ø¶Ø© (30-70%) â† Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ÙˆØ­ÙŠØ¯Ø© Ù„Ù€ None
        else:  # 30% < confidence < 70%
            is_matched = None  # â“ Ù…Ø´ Ù…ØªØ£ÙƒØ¯ - Ù…Ø­ØªØ§Ø¬ AI ÙÙŠ Stage 1
            skip_ai = False
            reason = 'ÙŠØ­ØªØ§Ø¬ ØªØ­Ù„ÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ'
        
        return {
            'confidence': confidence,
            'is_matched': is_matched,
            'reason': reason,
            'skip_ai': skip_ai,
            'details': scores
        }
    
    def get_missing_elements(
        self,
        policy_text: str,
        policy_type: str
    ) -> List[str]:
        """
        Get list of missing important elements
        """
        rules = self.POLICY_RULES.get(policy_type, {})
        text_lower = policy_text.lower()
        
        missing = []
        
        # Check required keywords
        for kw in rules.get('required_keywords', []):
            if kw not in text_lower:
                missing.append(f"ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© Ù…ÙÙ‚ÙˆØ¯Ø©: {kw}")
        
        # Check strong indicators
        found_strong = sum(
            1 for kw in rules.get('strong_indicators', [])
            if kw in text_lower
        )
        if found_strong == 0:
            missing.append("Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¤Ø´Ø±Ø§Øª Ù‚ÙˆÙŠØ© Ù„Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨")
        
        # Check minimum length
        if len(policy_text) < rules.get('minimum_length', 100):
            missing.append(
                f"Ø§Ù„Ù†Øµ Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹ (Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰: {rules.get('minimum_length')} Ø­Ø±Ù)"
            )
        
        return missing


def rule_based_policy_match(
    policy_type: str,
    policy_text: str
) -> Dict:
    """
    Standalone function for rule-based matching
    Used for graceful degradation when AI is unavailable
    """
    validator = PolicyValidator()
    result = validator.validate_and_score(policy_text, policy_type)
    
    return {
        'is_matched': result['is_matched'] or result['confidence'] > 0.6,
        'confidence': result['confidence'] * 100,  # Convert to percentage
        'reason': result['reason'],
        'method': 'rule_based',
        'details': result['details']
    }


def enhanced_policy_validation(
    policy_type: str,
    policy_text: str
) -> Tuple[bool, Dict]:
    """
    Enhanced Policy validation
    
    Returns:
        (should_use_ai, validation_result)
    """
    validator = PolicyValidator()
    result = validator.validate_and_score(policy_text, policy_type)
    
    should_use_ai = not result['skip_ai']
    
    app_logger.info(
        f"ğŸ“‹ Enhanced validation - Use AI: {should_use_ai}, "
        f"Confidence: {result['confidence']:.2%}"
    )
    
    return should_use_ai, result


# Pre-validation checks (before task creation)
def pre_validate_input(
    policy_text: str,
    policy_type: str
) -> Tuple[bool, Optional[str]]:
    """
    Quick pre-validation before creating Celery task
    
    Returns:
        (is_valid, error_message)
    """
    # Length check
    if len(policy_text) < 50:
        return False, "Ù†Øµ Ø§Ù„Ø³ÙŠØ§Ø³Ø© Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹ (Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ 50 Ø­Ø±Ù)"
    
    if len(policy_text) > 50000:
        return False, "Ù†Øµ Ø§Ù„Ø³ÙŠØ§Ø³Ø© Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹ (Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ 50,000 Ø­Ø±Ù)"
    
    # Basic content check
    if not policy_text.strip():
        return False, "Ù†Øµ Ø§Ù„Ø³ÙŠØ§Ø³Ø© ÙØ§Ø±Øº"
    
    # Check for meaningful content (not just spaces/symbols)
    words = re.findall(r'\w+', policy_text)
    if len(words) < 20:
        return False, "Ø§Ù„Ù†Øµ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ ÙƒØ§ÙÙ (Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ 20 ÙƒÙ„Ù…Ø©)"
    
    # Check for Arabic content
    arabic_chars = re.findall(r'[\u0600-\u06FF]', policy_text)
    if len(arabic_chars) < 30:
        return False, "Ø§Ù„Ù†Øµ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø¹Ø±Ø¨ÙŠ ÙƒØ§ÙÙ"
    
    return True, None